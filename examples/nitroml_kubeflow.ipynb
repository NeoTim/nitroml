{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 44.6M  100 44.6M    0     0   112M      0 --:--:-- --:--:-- --:--:--  111M\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# install kfp (https://kubeflow-pipelines.readthedocs.io/en/latest/source/kfp.html)\n",
    "!{sys.executable} -m pip install --user --upgrade -q kfp==0.4.0\n",
    "\n",
    "# Download skaffold and set it executable.\n",
    "!curl -Lo skaffold https://storage.googleapis.com/skaffold/releases/latest/skaffold-linux-amd64 && chmod +x skaffold && mv skaffold /home/jupyter/.local/bin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFX version: 0.22.0\n"
     ]
    }
   ],
   "source": [
    "# !{sys.executable} -m pip install --user --upgrade -q tfx==0.22.0\n",
    "# !{sys.executable} -m pip install --user --upgrade -q tfx==0.21.4\n",
    "!python3 -c \"import tfx; print('TFX version: {}'.format(tfx.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/home/jupyter/.local/bin\n"
     ]
    }
   ],
   "source": [
    "# Set `PATH` to include user python binary directory and a directory containing `skaffold`.\n",
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCP project ID:nitroml-brain-xgcp\n"
     ]
    }
   ],
   "source": [
    "# Read GCP project id from env.\n",
    "shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "GCP_PROJECT_ID=shell_output[0]\n",
    "print(\"GCP project ID:\" + GCP_PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set KFP Cluster End point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This refers to the KFP cluster endpoint\n",
    "ENDPOINT='ee1a2cabbbc2f13-dot-us-east1.pipelines.googleusercontent.com' # Enter your ENDPOINT here.\n",
    "if not ENDPOINT:\n",
    "    from absl import logging\n",
    "    logging.error('Set your ENDPOINT in this cell.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docker image name for the pipeline image \n",
    "IMAGE_NAME = 'nitroml_benchmark4'\n",
    "CUSTOM_TFX_IMAGE='gcr.io/' + GCP_PROJECT_ID + '/' + IMAGE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/AIHub/nitroml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PROJECT_DIR=os.path.join(os.path.expanduser(\"~\"), \"AIHub\" , 'nitroml')\n",
    "%cd {PROJECT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples import config\n",
    "PIPELINE_NAME=config.PIPELINE_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'titanic_new2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PIPELINE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the tfx pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLI\n",
      "Creating pipeline\n",
      "Detected Kubeflow.\n",
      "Use --engine flag if you intend to use a different orchestrator.\n",
      "Reading build spec from build.yaml\n",
      "No local setup.py, copying the directory and configuring the PYTHONPATH.\n",
      "Use skaffold to build the container image.\n",
      "/home/jupyter/.local/bin/skaffold\n",
      "New container image is built. Target image is available in the build spec file.\n",
      "['/home/jupyter/AIHub/nitroml/examples', '/home/jupyter/AIHub/nitroml/examples/..', '/opt/conda/lib/python37.zip', '/opt/conda/lib/python3.7', '/opt/conda/lib/python3.7/lib-dynload', '/home/jupyter/.local/lib/python3.7/site-packages', '/opt/conda/lib/python3.7/site-packages']\n",
      "/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/data_types.py:191: UserWarning: RuntimeParameter is only supported on KubeflowDagRunner currently.\n",
      "  warnings.warn('RuntimeParameter is only supported on KubeflowDagRunner '\n",
      "I0626 19:15:40.794073 139838116447616 dataset_info.py:361] Load dataset info from gs://artifacts.nitroml-brain-xgcp.appspot.com/tensorflow-datasets/titanic/2.0.0\n",
      "I0626 19:15:41.402069 139838116447616 tfds_dataset.py:46] Preparing dataset...\n",
      "I0626 19:15:41.432193 139838116447616 dataset_builder.py:282] Reusing dataset titanic (gs://artifacts.nitroml-brain-xgcp.appspot.com/tensorflow-datasets/titanic/2.0.0)\n",
      "I0626 19:15:41.432431 139838116447616 tfds_dataset.py:48] tfds.core.DatasetInfo(\n",
      "    name='titanic',\n",
      "    version=2.0.0,\n",
      "    description='Dataset describing the survival status of individual passengers on the Titanic. Missing values in the original dataset are represented using ?. Float and int missing values are replaced with -1, string missing values are replaced with 'Unknown'.',\n",
      "    homepage='https://www.openml.org/d/40945',\n",
      "    features=FeaturesDict({\n",
      "        'features': FeaturesDict({\n",
      "            'age': tf.float32,\n",
      "            'boat': tf.string,\n",
      "            'body': tf.int32,\n",
      "            'cabin': tf.string,\n",
      "            'embarked': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),\n",
      "            'fare': tf.float32,\n",
      "            'home.dest': tf.string,\n",
      "            'name': tf.string,\n",
      "            'parch': tf.int32,\n",
      "            'pclass': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "            'sex': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
      "            'sibsp': tf.int32,\n",
      "            'ticket': tf.string,\n",
      "        }),\n",
      "        'survived': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
      "    }),\n",
      "    total_num_examples=1309,\n",
      "    splits={\n",
      "        'train': 1309,\n",
      "    },\n",
      "    supervised_keys=('features', 'survived'),\n",
      "    citation=\"\"\"@ONLINE {titanic,\n",
      "    author = \"Frank E. Harrell Jr., Thomas Cason\",\n",
      "    title  = \"Titanic dataset\",\n",
      "    month  = \"oct\",\n",
      "    year   = \"2017\",\n",
      "    url    = \"https://www.openml.org/d/40945\"\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n",
      "I0626 19:15:41.433899 139838116447616 tfds_dataset.py:64] Splits: [name: \"train\"\n",
      "pattern: \"titanic-train.tfrecord-00000-of-00001\"\n",
      "]\n",
      "I0626 19:15:41.435887 139838116447616 component.py:131] Neither eval_config nor feature_slicing_spec is passed, the model is treated as estimator.\n",
      "W0626 19:15:41.436027 139838116447616 component.py:142] feature_slicing_spec is deprecated, please use eval_config instead.\n",
      "I0626 19:15:41.549641 139838116447616 nitroml.py:211] NitroML benchmarks:\n",
      "I0626 19:15:41.549877 139838116447616 nitroml.py:214] \tTitanicBenchmark.benchmark\n",
      "I0626 19:15:41.549983 139838116447616 nitroml.py:215] \t\tRUNNING\n",
      "I0626 19:15:41.559939 139838116447616 base_component.py:137] Adding upstream dependencies for component ImportExampleGen_TitanicBenchmark_benchmark\n",
      "I0626 19:15:41.561403 139838116447616 base_component.py:137] Adding upstream dependencies for component StatisticsGen_TitanicBenchmark_benchmark\n",
      "I0626 19:15:41.561557 139838116447616 base_component.py:139]    ->  Component: ImportExampleGen_TitanicBenchmark_benchmark\n",
      "I0626 19:15:41.562655 139838116447616 base_component.py:137] Adding upstream dependencies for component SchemaGen_TitanicBenchmark_benchmark\n",
      "I0626 19:15:41.562774 139838116447616 base_component.py:139]    ->  Component: StatisticsGen_TitanicBenchmark_benchmark\n",
      "I0626 19:15:41.564435 139838116447616 base_component.py:137] Adding upstream dependencies for component Transform_TitanicBenchmark_benchmark\n",
      "I0626 19:15:41.564562 139838116447616 base_component.py:139]    ->  Component: ImportExampleGen_TitanicBenchmark_benchmark\n",
      "I0626 19:15:41.564655 139838116447616 base_component.py:139]    ->  Component: SchemaGen_TitanicBenchmark_benchmark\n",
      "I0626 19:15:41.566144 139838116447616 base_component.py:137] Adding upstream dependencies for component Trainer_TitanicBenchmark_benchmark\n",
      "I0626 19:15:41.566257 139838116447616 base_component.py:139]    ->  Component: Transform_TitanicBenchmark_benchmark\n",
      "I0626 19:15:41.566345 139838116447616 base_component.py:139]    ->  Component: SchemaGen_TitanicBenchmark_benchmark\n",
      "I0626 19:15:41.567816 139838116447616 base_component.py:137] Adding upstream dependencies for component Evaluator_TitanicBenchmark_benchmark\n",
      "I0626 19:15:41.567925 139838116447616 base_component.py:139]    ->  Component: Trainer_TitanicBenchmark_benchmark\n",
      "I0626 19:15:41.568014 139838116447616 base_component.py:139]    ->  Component: ImportExampleGen_TitanicBenchmark_benchmark\n",
      "I0626 19:15:41.568994 139838116447616 base_component.py:137] Adding upstream dependencies for component BenchmarkResultPublisher_TitanicBenchmark_benchmark\n",
      "I0626 19:15:41.569102 139838116447616 base_component.py:139]    ->  Component: Evaluator_TitanicBenchmark_benchmark\n",
      "Pipeline compiled successfully.\n",
      "Pipeline package path: /home/jupyter/AIHub/nitroml/titanic_new2.tar.gz\n",
      "{'created_at': datetime.datetime(2020, 6, 26, 19, 15, 42, tzinfo=tzlocal()),\n",
      " 'default_version': {'code_source_url': None,\n",
      "                     'created_at': datetime.datetime(2020, 6, 26, 19, 15, 42, tzinfo=tzlocal()),\n",
      "                     'id': 'aef2b1bd-0f37-410f-aec5-3a5e4abe2a9b',\n",
      "                     'name': 'titanic_new2',\n",
      "                     'package_url': None,\n",
      "                     'parameters': [{'name': 'pipeline-root',\n",
      "                                     'value': 'gs://artifacts.nitroml-brain-xgcp.appspot.com/tfx_pipeline_output'}],\n",
      "                     'resource_references': [{'key': {'id': 'aef2b1bd-0f37-410f-aec5-3a5e4abe2a9b',\n",
      "                                                      'type': 'PIPELINE'},\n",
      "                                              'name': None,\n",
      "                                              'relationship': 'OWNER'}]},\n",
      " 'description': None,\n",
      " 'error': None,\n",
      " 'id': 'aef2b1bd-0f37-410f-aec5-3a5e4abe2a9b',\n",
      " 'name': 'titanic_new2',\n",
      " 'parameters': [{'name': 'pipeline-root',\n",
      "                 'value': 'gs://artifacts.nitroml-brain-xgcp.appspot.com/tfx_pipeline_output'}],\n",
      " 'url': None}\n",
      "Please access the pipeline detail page at http://ee1a2cabbbc2f13-dot-us-east1.pipelines.googleusercontent.com/#/pipelines/details/aef2b1bd-0f37-410f-aec5-3a5e4abe2a9b\n",
      "Pipeline \"titanic_new2\" created successfully.\n"
     ]
    }
   ],
   "source": [
    "!tfx pipeline create  \\\n",
    "--pipeline-path=examples/kubeflow_dag_runner.py \\\n",
    "--endpoint={ENDPOINT} \\\n",
    "--build-target-image={CUSTOM_TFX_IMAGE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLI\n",
      "Creating a run for pipeline: titanic_new2\n",
      "Detected Kubeflow.\n",
      "Use --engine flag if you intend to use a different orchestrator.\n",
      "Run created for pipeline: titanic_new2\n",
      "+-----------------+--------------------------------------+----------+---------------------------+-------------------------------------------------------------------------------------------------------------------------+\n",
      "| pipeline_name   | run_id                               | status   | created_at                | link                                                                                                                    |\n",
      "+=================+======================================+==========+===========================+=========================================================================================================================+\n",
      "| titanic_new2    | a8e0681d-a156-4810-b8a0-2e74cf2c6157 |          | 2020-06-26T19:15:52+00:00 | http://ee1a2cabbbc2f13-dot-us-east1.pipelines.googleusercontent.com/#/runs/details/a8e0681d-a156-4810-b8a0-2e74cf2c6157 |\n",
      "+-----------------+--------------------------------------+----------+---------------------------+-------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!tfx run create --pipeline-name={config.PIPELINE_NAME} --endpoint={ENDPOINT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLI\n",
      "Updating pipeline\n",
      "Detected Kubeflow.\n",
      "Use --engine flag if you intend to use a different orchestrator.\n",
      "Reading build spec from build.yaml\n",
      "Use skaffold to build the container image.\n",
      "/home/jupyter/.local/bin/skaffold\n",
      "New container image is built. Target image is available in the build spec file.\n",
      "['/home/jupyter/AIHub/nitroml/examples', '/home/jupyter/AIHub/nitroml/examples/..', '/opt/conda/lib/python37.zip', '/opt/conda/lib/python3.7', '/opt/conda/lib/python3.7/lib-dynload', '/home/jupyter/.local/lib/python3.7/site-packages', '/opt/conda/lib/python3.7/site-packages']\n",
      "/home/jupyter/.local/lib/python3.7/site-packages/tfx/orchestration/data_types.py:191: UserWarning: RuntimeParameter is only supported on KubeflowDagRunner currently.\n",
      "  warnings.warn('RuntimeParameter is only supported on KubeflowDagRunner '\n",
      "I0626 19:47:13.368769 140310186665344 dataset_info.py:361] Load dataset info from gs://artifacts.nitroml-brain-xgcp.appspot.com/tensorflow-datasets/titanic/2.0.0\n",
      "I0626 19:47:14.028251 140310186665344 tfds_dataset.py:46] Preparing dataset...\n",
      "I0626 19:47:14.060121 140310186665344 dataset_builder.py:282] Reusing dataset titanic (gs://artifacts.nitroml-brain-xgcp.appspot.com/tensorflow-datasets/titanic/2.0.0)\n",
      "I0626 19:47:14.060352 140310186665344 tfds_dataset.py:48] tfds.core.DatasetInfo(\n",
      "    name='titanic',\n",
      "    version=2.0.0,\n",
      "    description='Dataset describing the survival status of individual passengers on the Titanic. Missing values in the original dataset are represented using ?. Float and int missing values are replaced with -1, string missing values are replaced with 'Unknown'.',\n",
      "    homepage='https://www.openml.org/d/40945',\n",
      "    features=FeaturesDict({\n",
      "        'features': FeaturesDict({\n",
      "            'age': tf.float32,\n",
      "            'boat': tf.string,\n",
      "            'body': tf.int32,\n",
      "            'cabin': tf.string,\n",
      "            'embarked': ClassLabel(shape=(), dtype=tf.int64, num_classes=4),\n",
      "            'fare': tf.float32,\n",
      "            'home.dest': tf.string,\n",
      "            'name': tf.string,\n",
      "            'parch': tf.int32,\n",
      "            'pclass': ClassLabel(shape=(), dtype=tf.int64, num_classes=3),\n",
      "            'sex': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
      "            'sibsp': tf.int32,\n",
      "            'ticket': tf.string,\n",
      "        }),\n",
      "        'survived': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
      "    }),\n",
      "    total_num_examples=1309,\n",
      "    splits={\n",
      "        'train': 1309,\n",
      "    },\n",
      "    supervised_keys=('features', 'survived'),\n",
      "    citation=\"\"\"@ONLINE {titanic,\n",
      "    author = \"Frank E. Harrell Jr., Thomas Cason\",\n",
      "    title  = \"Titanic dataset\",\n",
      "    month  = \"oct\",\n",
      "    year   = \"2017\",\n",
      "    url    = \"https://www.openml.org/d/40945\"\n",
      "    }\"\"\",\n",
      "    redistribution_info=,\n",
      ")\n",
      "\n",
      "I0626 19:47:14.061767 140310186665344 tfds_dataset.py:64] Splits: [name: \"train\"\n",
      "pattern: \"titanic-train.tfrecord-00000-of-00001\"\n",
      "]\n",
      "I0626 19:47:14.064177 140310186665344 component.py:131] Neither eval_config nor feature_slicing_spec is passed, the model is treated as estimator.\n",
      "W0626 19:47:14.064314 140310186665344 component.py:142] feature_slicing_spec is deprecated, please use eval_config instead.\n",
      "I0626 19:47:14.165752 140310186665344 nitroml.py:211] NitroML benchmarks:\n",
      "I0626 19:47:14.165995 140310186665344 nitroml.py:214] \tTitanicBenchmark.benchmark\n",
      "I0626 19:47:14.166116 140310186665344 nitroml.py:215] \t\tRUNNING\n",
      "I0626 19:47:14.174528 140310186665344 base_component.py:137] Adding upstream dependencies for component ImportExampleGen_TitanicBenchmark_benchmark\n",
      "I0626 19:47:14.176151 140310186665344 base_component.py:137] Adding upstream dependencies for component StatisticsGen_TitanicBenchmark_benchmark\n",
      "I0626 19:47:14.176313 140310186665344 base_component.py:139]    ->  Component: ImportExampleGen_TitanicBenchmark_benchmark\n",
      "I0626 19:47:14.177438 140310186665344 base_component.py:137] Adding upstream dependencies for component SchemaGen_TitanicBenchmark_benchmark\n",
      "I0626 19:47:14.177564 140310186665344 base_component.py:139]    ->  Component: StatisticsGen_TitanicBenchmark_benchmark\n",
      "I0626 19:47:14.179175 140310186665344 base_component.py:137] Adding upstream dependencies for component Transform_TitanicBenchmark_benchmark\n",
      "I0626 19:47:14.179294 140310186665344 base_component.py:139]    ->  Component: SchemaGen_TitanicBenchmark_benchmark\n",
      "I0626 19:47:14.179385 140310186665344 base_component.py:139]    ->  Component: ImportExampleGen_TitanicBenchmark_benchmark\n",
      "I0626 19:47:14.181013 140310186665344 base_component.py:137] Adding upstream dependencies for component Trainer_TitanicBenchmark_benchmark\n",
      "I0626 19:47:14.181128 140310186665344 base_component.py:139]    ->  Component: Transform_TitanicBenchmark_benchmark\n",
      "I0626 19:47:14.181221 140310186665344 base_component.py:139]    ->  Component: SchemaGen_TitanicBenchmark_benchmark\n",
      "I0626 19:47:14.182722 140310186665344 base_component.py:137] Adding upstream dependencies for component Evaluator_TitanicBenchmark_benchmark\n",
      "I0626 19:47:14.182990 140310186665344 base_component.py:139]    ->  Component: Trainer_TitanicBenchmark_benchmark\n",
      "I0626 19:47:14.183121 140310186665344 base_component.py:139]    ->  Component: ImportExampleGen_TitanicBenchmark_benchmark\n",
      "I0626 19:47:14.184212 140310186665344 base_component.py:137] Adding upstream dependencies for component BenchmarkResultPublisher_TitanicBenchmark_benchmark\n",
      "I0626 19:47:14.184337 140310186665344 base_component.py:139]    ->  Component: Evaluator_TitanicBenchmark_benchmark\n",
      "Pipeline compiled successfully.\n",
      "Pipeline package path: /home/jupyter/AIHub/nitroml/titanic_new2.tar.gz\n",
      "{'code_source_url': None,\n",
      " 'created_at': datetime.datetime(2020, 6, 26, 19, 47, 15, tzinfo=tzlocal()),\n",
      " 'id': 'd95fb9ce-b43a-4656-9efd-5a37cf145500',\n",
      " 'name': 'titanic_new2_20200626194715',\n",
      " 'package_url': None,\n",
      " 'parameters': [{'name': 'pipeline-root',\n",
      "                 'value': 'gs://artifacts.nitroml-brain-xgcp.appspot.com/tfx_pipeline_output'}],\n",
      " 'resource_references': [{'key': {'id': 'aef2b1bd-0f37-410f-aec5-3a5e4abe2a9b',\n",
      "                                  'type': 'PIPELINE'},\n",
      "                          'name': None,\n",
      "                          'relationship': 'OWNER'}]}\n",
      "Please access the pipeline detail page at http://ee1a2cabbbc2f13-dot-us-east1.pipelines.googleusercontent.com/#/pipelines/details/aef2b1bd-0f37-410f-aec5-3a5e4abe2a9b\n",
      "Pipeline \"titanic_new2\" updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Update the pipeline\n",
    "!tfx pipeline update \\\n",
    "--pipeline-path=examples/kubeflow_dag_runner.py \\\n",
    "--endpoint={ENDPOINT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLI\n",
      "Creating a run for pipeline: titanic_new2\n",
      "Detected Kubeflow.\n",
      "Use --engine flag if you intend to use a different orchestrator.\n",
      "Run created for pipeline: titanic_new2\n",
      "+-----------------+--------------------------------------+----------+---------------------------+-------------------------------------------------------------------------------------------------------------------------+\n",
      "| pipeline_name   | run_id                               | status   | created_at                | link                                                                                                                    |\n",
      "+=================+======================================+==========+===========================+=========================================================================================================================+\n",
      "| titanic_new2    | c336ddf4-1347-42f4-822d-e2d20ec722c6 |          | 2020-06-26T19:47:22+00:00 | http://ee1a2cabbbc2f13-dot-us-east1.pipelines.googleusercontent.com/#/runs/details/c336ddf4-1347-42f4-822d-e2d20ec722c6 |\n",
      "+-----------------+--------------------------------------+----------+---------------------------+-------------------------------------------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!tfx run create --pipeline-name {PIPELINE_NAME} --endpoint={ENDPOINT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfx_image = os.environ.get('KUBEFLOW_TFX_IMAGE', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print (tfx_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-1.m48",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-1:m48"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
